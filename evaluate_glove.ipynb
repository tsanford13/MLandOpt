{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import timeit\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''A BATS_Analogy is an analogy from the BATS test set. It may allow\n",
    "multiple correct answers! While most analogies are of the form\n",
    "a:b::c:d (read as \"a is to be as c is to d\") a BATS Analogy is of the form\n",
    "a:b1,b2,...,bn::c:d,d1,d2,...,dn (read as \"a is to b1 or b2 or ... or bn as \n",
    "c is to d1 or d2 or ... or dn\") an example would be:\n",
    "\"snake is to nest/pit/acquarium as tiger is to den/cage.\"'''\n",
    "class BATS_Analogy:\n",
    "    def __init__(self, a, b_set, c, d_set):\n",
    "        self.a = a\n",
    "        self.b_set = b_set\n",
    "        self.c = c\n",
    "        self.solution_set = d_set\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''takes two matrices A and B and returns \n",
    "A@B. If A and B are normalized then this is equivalent\n",
    "to calculating the cosine similarity of each row of A with\n",
    "each column of B. i.e. the cosine similarity of the ith row of A\n",
    "with the jth column of B is given by (A@B)[i,j]'''\n",
    "def cosine_similarity_normalized(A, B):\n",
    "    return A@B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_batch_accuracy(analogies, embeddings, words_to_indices, indices_to_words, sim):\n",
    "    num_correct = 0\n",
    "    analogy_predictions_indices = dict()\n",
    "    start = 0\n",
    "    all_prediction_matrices = []\n",
    "    num_predictions = 0\n",
    "    for analogy in analogies:\n",
    "        num_predictions += len(analogy.b_set)\n",
    "        end = start + len(analogy.b_set)\n",
    "        analogy_predictions_indices[analogy] = (start,end)\n",
    "        start = end\n",
    "       # temp = np.empty((len(analogy.b_set), embeddings.shape[1]), dtype=np.float32)\n",
    "        \n",
    "    all_predictions = np.empty((num_predictions, embeddings.shape[1]), dtype=np.float32)\n",
    "    for analogy in analogies:\n",
    "        offset = analogy_predictions_indices.get(analogy)[0]\n",
    "        for i in range(analogy_predictions_indices.get(analogy)[1] - offset):\n",
    "            all_predictions[i + offset] = embeddings[words_to_indices.get(analogy.b_set[i])]\n",
    "        start = analogy_predictions_indices.get(analogy)[0]\n",
    "        end = analogy_predictions_indices.get(analogy)[1]\n",
    "        all_predictions[range(start, end)] += embeddings[words_to_indices.get(analogy.c)]\n",
    "        all_predictions[range(start, end)] -= embeddings[words_to_indices.get(analogy.a)]\n",
    "     \n",
    "    '''\n",
    "        for i in range(len(analogy.b_set)):\n",
    "            temp[i] = embeddings[words_to_indices.get(analogy.b_set[i])]\n",
    "        temp += embeddings[words_to_indices.get(analogy.c)]\n",
    "        temp -= embeddings[words_to_indices.get(analogy.a)]\n",
    "        all_prediction_matrices.append(temp)\n",
    "        '''\n",
    "    #all_predictions = np.concatenate(all_prediction_matrices, axis=0)\n",
    "    all_distances = sim(embeddings, all_predictions.T)\n",
    "    for analogy in analogies:\n",
    "        start_index = analogy_predictions_indices.get(analogy)[0]\n",
    "        a_ind = words_to_indices.get(analogy.a)\n",
    "        b_indices = [words_to_indices.get(b) for b in analogy.b_set]\n",
    "        c_ind = words_to_indices.get(analogy.c)\n",
    "        for i in range(len(b_indices)):\n",
    "            all_distances[a_ind,  start_index + i] = np.NINF \n",
    "            all_distances[b_indices[i], start_index + i] = np.NINF\n",
    "            all_distances[c_ind, start_index + i] = np.NINF\n",
    "    prediction_indices = np.argmax(all_distances, axis=0)\n",
    "    for analogy in analogies:\n",
    "        start_ind = analogy_predictions_indices[analogy][0]\n",
    "        end_ind = analogy_predictions_indices[analogy][1]\n",
    "        for i in range(start_ind, end_ind):\n",
    "            if indices_to_words.get(prediction_indices[i]) in analogy.solution_set:\n",
    "                num_correct += 1\n",
    "                break\n",
    "    return num_correct\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''construct_analogies takes a list of lines from a BATS file and constructs the corresponding analogy lines.\n",
    "Each of the original line has a pair, e.g. \"cat cats\" or \"dog dogs\" and the corresponding analogy would be \n",
    "\"cat is to cats as dog is to dogs\" '''\n",
    "def construct_analogies(lines):\n",
    "    analogies = []\n",
    "    for i in range(len(lines)):\n",
    "        for j in range(len(lines)):\n",
    "            if i == j:\n",
    "                pass \n",
    "            else:\n",
    "                split_first_line = lines[i].split()\n",
    "                a = split_first_line[0]\n",
    "                b_set = split_first_line[1].split(\"/\")\n",
    "                split_second_line = lines[j].split()\n",
    "                c = split_second_line[0]\n",
    "                solution_set = split_second_line[1].split(\"/\")\n",
    "                analogies.append(BATS_Analogy(a, b_set, c, solution_set))\n",
    "    return analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analogies(filepath):\n",
    "    file = open(filepath, 'r')\n",
    "    lines = file.readlines()\n",
    "    analogies = construct_analogies(lines)\n",
    "    return analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load_vectors takes a filepath to a file containing word vectors as a .txt file\n",
    "of the format word [vector components] e.g. for a 4dimensional vector one line could be\n",
    "\"the 0.004 -10.499 0.000 \\n\"\n",
    "the function returns a numpy array of size vxd where v is the size of the vocabulary and \n",
    "d is the length of each vector. The function also returns two dictionaries, one of which\n",
    "has words as keys and indices as values and the other has indices as keys and words as vectors.\n",
    "'''\n",
    "def load_vectors(filepath, normalize=1):\n",
    "    word_to_index = dict()\n",
    "    index_to_word = dict()\n",
    "    file = open(filepath, 'r', encoding='utf-8')\n",
    "    lines = file.readlines()\n",
    "    embeddings = np.ones((len(lines), len(lines[0].split())-1), dtype=np.float32)\n",
    "    for i in range(len(lines)):\n",
    "        vec_info = lines[i].split()\n",
    "        word = vec_info[0]\n",
    "        vec_nums = [np.float32(component) for component in vec_info[1:]]\n",
    "        vec = np.array(vec_nums)\n",
    "        if normalize:\n",
    "            #normalize vectors\n",
    "            vec = vec/(np.linalg.norm(vec))\n",
    "        embeddings[i] = vec\n",
    "        word_to_index[word] = i \n",
    "        index_to_word[i] = word\n",
    "    return embeddings, word_to_index, index_to_word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unsolvable(analogies, word_to_index):\n",
    "    solvable_analogies = []\n",
    "    for analogy in analogies:\n",
    "        a_ind = word_to_index.get(analogy.a)\n",
    "        c_ind = word_to_index.get(analogy.c)\n",
    "        if a_ind == None or c_ind == None:\n",
    "            pass\n",
    "        else:\n",
    "            b_set_known = []\n",
    "            b_all_null = True\n",
    "            for b in analogy.b_set:\n",
    "                if word_to_index.get(b) != None:\n",
    "                    b_all_null = False\n",
    "                    b_set_known.append(b)\n",
    "                else:\n",
    "                    continue\n",
    "            if b_all_null:\n",
    "                pass\n",
    "            else:\n",
    "                solvable_analogies.append(BATS_Analogy(analogy.a, b_set_known, analogy.c, analogy.solution_set))\n",
    "    return solvable_analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_path = \"./Pretrained_Vectors/glove.6B/glove.6B.50d/glove.6B.50d.txt\"\n",
    "embeddings, word_to_index, index_to_word = load_vectors(vector_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bats_path = \"./BATS_3.0/BATS_3.0/4_Lexicographic_semantics/L03 [hyponyms - misc].txt\"\n",
    "analogies = get_analogies(bats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "analogies = remove_unsolvable(analogies, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_on_file(filepath, embeddings, word_to_index, index_to_word, sim, batch_size=100):\n",
    "    analogies = get_analogies(filepath)\n",
    "    analogies = remove_unsolvable(analogies, word_to_index)\n",
    "    i = 0\n",
    "    total_correct = 0\n",
    "    while i < len(analogies):\n",
    "        end_ind = min(i+batch_size, len(analogies))\n",
    "        batch = analogies[i:end_ind]\n",
    "        total_correct += calculate_batch_accuracy(batch, embeddings, word_to_index, index_to_word, sim)\n",
    "        i += batch_size\n",
    "        print(\"Completed batch: \", i, \"through \", end_ind )\n",
    "    return total_correct, len(analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_analogy_tests(test_filepaths, model_name, embeddings, word_to_index, index_to_word, sim):\n",
    "    results = []\n",
    "    for filepath in test_filepaths:\n",
    "        temp = filepath.split(\"/\")\n",
    "        filename = temp[-1]\n",
    "        recorded_file = False\n",
    "        batch_size = 512\n",
    "        while not recorded_file:\n",
    "            try:\n",
    "                test_correct, test_attempted = compute_accuracy_on_file(filepath, embeddings, word_to_index, index_to_word, sim)\n",
    "                results.append({'Model': model_name, 'Test': filename, 'Total Correct': test_correct, 'Total Attempted': test_attempted})\n",
    "                recorded_file = True\n",
    "            except:\n",
    "                if batch_size == 1:\n",
    "                    print(\"Failed to Solve Analogies with batch_size = 1 on file\", filename)\n",
    "                    break\n",
    "                batch_size = batch_size/2\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "correct, attempted = compute_accuracy_on_file(bats_path, embeddings, word_to_index, index_to_word, cosine_similarity_normalized)\n",
    "diff = float(time.time() - start)\n",
    "print(\"solved {0} out of {0} analogies in {1:.4f} seconds\".format(correct, attempted, diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2401\n"
     ]
    }
   ],
   "source": [
    "print(len(analogies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_to_index.get(analogies[0].b_set[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analogies[0].b_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [index_to_word.get(b) for b in analogies[0].b_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_to_index.get(analogies[4].b_set[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = int(10)\n",
    "var2 = 0.003\n",
    "print(\"test{0} solved {1:.4f}\".format(var1, var2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"ab/cdef/fdfg\"\n",
    "test = string.split(\"/\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results.append({ 'Model': 'glove.6B.50d', 'Test': 'L04 [meronyms - substance]', 'Total Correct': 10, 'Total Attempted': 100})\n",
    "results.append({ 'Model': 'glove.6B.50d', 'Test': 'L05 [meronyms - substance]', 'Total Correct': 10, 'Total Attempted': 100})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'w') as json_file:\n",
    "    json.dump(results, json_file)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.txt', 'r') as json_file:\n",
    "    test_open = json.load(json_file)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_OPT_Project",
   "language": "python",
   "name": "ml_opt_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
